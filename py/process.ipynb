{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bb473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         city_clean iso2      lat       lng\n",
      "0     NEW BRUNSWICK   US  40.4870  -74.4450\n",
      "588        SHANGHAI   CN  31.2286  121.4747\n",
      "681           BASEL   CH  47.5606    7.5906\n",
      "1069         RAHWAY   US  40.6077  -74.2807\n",
      "1475       NEW YORK   US  40.6943  -73.9249\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取原始总部城市数据\n",
    "df_geo = pd.read_csv(\"E:/Documents/UCL/UCLminiproject/Group/world_com_city.csv\")\n",
    "\n",
    "# 去重：每家公司只保留一条总部记录\n",
    "df_geo_hq = df_geo.drop_duplicates(subset=[\"company\"])\n",
    "\n",
    "# 保留总部城市、国家和经纬度字段\n",
    "df_geo_hq_cleaned = df_geo_hq[[\"Parent_City_clean\", \"Country_head\", \"head_lat\", \"head_lng\"]].dropna()\n",
    "\n",
    "# 重命名列，便于后续合并\n",
    "df_geo_hq_cleaned = df_geo_hq_cleaned.rename(columns={\n",
    "    \"Parent_City_clean\": \"city_clean\",\n",
    "    \"Country_head\": \"iso2\",\n",
    "    \"head_lat\": \"lat\",\n",
    "    \"head_lng\": \"lng\"\n",
    "})\n",
    "\n",
    "# 可选：查看结果前几行\n",
    "print(df_geo_hq_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707d25ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company name Latin alphabet</th>\n",
       "      <th>Country ISO code</th>\n",
       "      <th>City\\nLatin Alphabet</th>\n",
       "      <th>NACE Rev. 2, core code (4 digits)</th>\n",
       "      <th>Operating revenue (Turnover)\\nth USD Last avail. yr</th>\n",
       "      <th>Number of employees\\nLast avail. yr</th>\n",
       "      <th>Profit margin\\nLast avail. yr</th>\n",
       "      <th>MSCI - Overall indicative ESG score\\nLast avail. yr</th>\n",
       "      <th>MSCI - Environmental pillar indicative score\\nLast avail. yr</th>\n",
       "      <th>MSCI - Social pillar indicative score\\nLast avail. yr</th>\n",
       "      <th>MSCI - Governance pillar indicative score\\nLast avail. yr</th>\n",
       "      <th>Business line - Sales\\nth USD</th>\n",
       "      <th>label</th>\n",
       "      <th>function_category</th>\n",
       "      <th>PS_sales</th>\n",
       "      <th>RS_sales</th>\n",
       "      <th>SS_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>JOHNSON &amp; JOHNSON</td>\n",
       "      <td>US</td>\n",
       "      <td>NEW BRUNSWICK</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>88821000.0</td>\n",
       "      <td>138100</td>\n",
       "      <td>18.787</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>56965000.0</td>\n",
       "      <td>innovative medicine</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56965000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31857000.0</td>\n",
       "      <td>medtech</td>\n",
       "      <td>PS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88822000.0</td>\n",
       "      <td>segment total</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88822000.0</td>\n",
       "      <td>consolidated total</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14574000.0</td>\n",
       "      <td>innovative medicine</td>\n",
       "      <td>RS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Company name Latin alphabet Country ISO code  \\\n",
       "0         1.0           JOHNSON & JOHNSON               US   \n",
       "1         NaN                         NaN              NaN   \n",
       "2         NaN                         NaN              NaN   \n",
       "3         NaN                         NaN              NaN   \n",
       "4         NaN                         NaN              NaN   \n",
       "\n",
       "  City\\nLatin Alphabet  NACE Rev. 2, core code (4 digits)  \\\n",
       "0        NEW BRUNSWICK                             2120.0   \n",
       "1                  NaN                                NaN   \n",
       "2                  NaN                                NaN   \n",
       "3                  NaN                                NaN   \n",
       "4                  NaN                                NaN   \n",
       "\n",
       "   Operating revenue (Turnover)\\nth USD Last avail. yr  \\\n",
       "0                                         88821000.0     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  Number of employees\\nLast avail. yr Profit margin\\nLast avail. yr  \\\n",
       "0                              138100                        18.787   \n",
       "1                                 NaN                           NaN   \n",
       "2                                 NaN                           NaN   \n",
       "3                                 NaN                           NaN   \n",
       "4                                 NaN                           NaN   \n",
       "\n",
       "   MSCI - Overall indicative ESG score\\nLast avail. yr  \\\n",
       "0                                                3.5     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   MSCI - Environmental pillar indicative score\\nLast avail. yr  \\\n",
       "0                                                1.4              \n",
       "1                                                NaN              \n",
       "2                                                NaN              \n",
       "3                                                NaN              \n",
       "4                                                NaN              \n",
       "\n",
       "   MSCI - Social pillar indicative score\\nLast avail. yr  \\\n",
       "0                                                3.2       \n",
       "1                                                NaN       \n",
       "2                                                NaN       \n",
       "3                                                NaN       \n",
       "4                                                NaN       \n",
       "\n",
       "   MSCI - Governance pillar indicative score\\nLast avail. yr  \\\n",
       "0                                                4.6           \n",
       "1                                                NaN           \n",
       "2                                                NaN           \n",
       "3                                                NaN           \n",
       "4                                                NaN           \n",
       "\n",
       "   Business line - Sales\\nth USD                label function_category  \\\n",
       "0                     56965000.0  innovative medicine                RS   \n",
       "1                     31857000.0              medtech                PS   \n",
       "2                     88822000.0        segment total             OTHER   \n",
       "3                     88822000.0   consolidated total             OTHER   \n",
       "4                     14574000.0  innovative medicine                RS   \n",
       "\n",
       "   PS_sales    RS_sales  SS_sales  \n",
       "0       0.0  56965000.0       0.0  \n",
       "1       NaN         NaN       NaN  \n",
       "2       NaN         NaN       NaN  \n",
       "3       NaN         NaN       NaN  \n",
       "4       NaN         NaN       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 读取原始文件（已标注功能分类的）\n",
    "df = pd.read_excel(\"E:/Documents/UCL/UCLminiproject/Group/TOP2000_labeled_expert.xlsx\")  # 替换为你的文件名\n",
    "\n",
    "# 2. 确保销售额是数字\n",
    "df[\"Business line - Sales\\nth USD\"] = pd.to_numeric(df[\"Business line - Sales\\nth USD\"], errors=\"coerce\")\n",
    "\n",
    "# 3. 汇总销售额（按公司 + 功能类别）\n",
    "sales_sum = (\n",
    "    df[df[\"function_category\"].isin([\"RS\", \"PS\", \"SS\"])]\n",
    "    .groupby([\"Company name Latin alphabet\", \"function_category\"])[\"Business line - Sales\\nth USD\"]\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    "    .rename(columns={\"RS\": \"RS_sales\", \"PS\": \"PS_sales\", \"SS\": \"SS_sales\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 4. 合并回原始数据（保留所有列，按公司名合并）\n",
    "df_with_sales = df.merge(sales_sum, how=\"left\", on=\"Company name Latin alphabet\")\n",
    "\n",
    "# 5. 查看结果\n",
    "df_with_sales.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e567100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\uclsoftware\\python\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\uclsoftware\\python\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.1 MB 7.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 7.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.1 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.1 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.0 scikit-learn-1.6.1 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb37d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: 读取数据\n",
    "df = pd.read_excel(\"E:/Documents/UCL/UCLminiproject/Group/TOP2000_corrected_ffill_sales.xlsx\")  # 替换为你的文件路径\n",
    "\n",
    "# Step 2: 选择构建韧性指数所需的字段\n",
    "cols = {\n",
    "    \"Operating revenue (Turnover)\\nth USD Last avail. yr\": \"scale\",\n",
    "    \"MSCI - Overall indicative ESG score\\nLast avail. yr\": \"esg_total\",\n",
    "    \"MSCI - Environmental pillar indicative score\\nLast avail. yr\": \"esg_env\",\n",
    "    \"MSCI - Social pillar indicative score\\nLast avail. yr\": \"esg_soc\",\n",
    "    \"MSCI - Governance pillar indicative score\\nLast avail. yr\": \"esg_gov\",\n",
    "    \"functional_diversity\": \"func_div\"\n",
    "}\n",
    "df_renamed = df[list(cols.keys())].rename(columns=cols)\n",
    "\n",
    "# Step 3: 删除缺失值（可选）\n",
    "for col in df_renamed.columns:\n",
    "    df_renamed[col] = pd.to_numeric(df_renamed[col], errors=\"coerce\")\n",
    "\n",
    "df_clean = df_renamed.dropna()\n",
    "\n",
    "# Step 4: Min-Max 归一化\n",
    "scaler = MinMaxScaler()\n",
    "normalized = scaler.fit_transform(df_clean)\n",
    "df_scaled = pd.DataFrame(normalized, columns=df_clean.columns)\n",
    "\n",
    "# Step 5: 计算韧性指数（等权平均）\n",
    "df_scaled[\"resilience_index\"] = df_scaled.mean(axis=1)\n",
    "\n",
    "# Step 6: 合并回原始公司数据\n",
    "df_result = df.copy()\n",
    "df_result[\"resilience_index\"] = None\n",
    "df_result.loc[df_clean.index, \"resilience_index\"] = df_scaled[\"resilience_index\"].values\n",
    "\n",
    "# Step 7: 保存为新文件\n",
    "df_result.to_excel(\"TOP2000_with_resilience_index.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34aef9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总记录数： 4587\n",
      "未匹配经纬度的记录数： 79\n",
      "已匹配经纬度的记录数： 4508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 TOP2000 数据\n",
    "df_companies = pd.read_excel(\"E:/Documents/UCL/UCLminiproject/Group/TOP2000_with_resilience_index.xlsx\")\n",
    "\n",
    "# 去除空城市和国家代码行\n",
    "df_companies = df_companies.dropna(subset=[\"City\", \"ISO\"])\n",
    "\n",
    "# 清洗城市和国家字段\n",
    "df_companies[\"city_cleaned\"] = (\n",
    "    df_companies[\"City\"]\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .str.replace(r\",.*$\", \"\", regex=True)\n",
    "    .str.replace(r'\\b(KU|SHI|CITY|SI|DISTRICT)\\b', '', regex=True)\n",
    "    .str.replace(r'\\s{2,}', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "df_companies[\"ISO\"] = df_companies[\"ISO\"].str.strip().str.upper()\n",
    "\n",
    "# ✅ 匹配总部经纬度\n",
    "df_merged = pd.merge(\n",
    "    df_companies,\n",
    "    df_geo_hq_cleaned,\n",
    "    left_on=[\"city_cleaned\", \"ISO\"],\n",
    "    right_on=[\"city_clean\", \"iso2\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 查看匹配情况\n",
    "print(\"总记录数：\", len(df_merged))\n",
    "print(\"未匹配经纬度的记录数：\", df_merged['lat'].isna().sum())\n",
    "print(\"已匹配经纬度的记录数：\", df_merged['lat'].notna().sum())\n",
    "\n",
    "# 可选：保存结果\n",
    "df_merged.to_csv(\"TOP2000_with_coords.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ca755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "MILANO                    23\n",
      "MINATO KU                 12\n",
      "WIEN                       9\n",
      "CHIYODA KU                 9\n",
      "CHUO KU                    7\n",
      "GRAND CAYMAN               6\n",
      "HANGZHOU CITY              6\n",
      "DUBLIN 2                   5\n",
      "OSAKA SHI CHUO KU          5\n",
      "MUENCHEN                   5\n",
      "BRUXELLES                  4\n",
      "WUXI CITY                  4\n",
      "SUZHOU CITY                4\n",
      "YONGIN-SI                  4\n",
      "TAIZHOU CITY, ZHEJIANG     4\n",
      "TOYAMA SHI                 4\n",
      "JAKARTA, JAVA              3\n",
      "PUURS-SINT-AMANDS          3\n",
      "SHIJIAZHUANG CITY          3\n",
      "GWACHEON-SI                3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unmatched = df_companies[~df_companies['city'].isin(df_geo['city_clean'])]\n",
    "print(unmatched['city'].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03644b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_27500\\892933815.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['geometry'] = gdf['geometry'].buffer(0.5)  # 0.1度，大概11km半径\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 读取点数据\n",
    "gdf = gpd.read_file(\"E:/Downloads/City_level_resilience_data_with_clusters.geojson\")\n",
    "\n",
    "# 创建缓冲polygon，单位是度（建议试 0.1 ~ 0.5 km 的转换）\n",
    "gdf['geometry'] = gdf['geometry'].buffer(0.5)  # 0.1度，大概11km半径\n",
    "\n",
    "# 保存为新的polygon geojson\n",
    "gdf.to_file(\"E:/Downloads/City_level_resilience_data_polygons.geojson\", driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f4ae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry\n",
      "(110.3488, 20.0186)    2\n",
      "(-81.3811, 19.295)     2\n",
      "(117.2273, 31.8206)    2\n",
      "(117.0207, 36.6702)    2\n",
      "(91.1719, 29.6534)     2\n",
      "(125.326, 43.897)      2\n",
      "(112.939, 28.228)      2\n",
      "(126.6409, 45.7576)    2\n",
      "(118.7789, 32.0608)    2\n",
      "(121.6245, 29.8603)    2\n",
      "(126.9833, 37.5667)    2\n",
      "(116.964, 33.648)      2\n",
      "(-79.3733, 43.7417)    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# 直接读取 geojson\n",
    "gdf = gpd.read_file('E:/Documents/UCL/UCLminiproject/demo/City_level_resilience_data_with_clusters.geojson')\n",
    "\n",
    "# 提取经纬度\n",
    "coords = gdf.geometry.apply(lambda geom: (geom.x, geom.y))\n",
    "\n",
    "# 检查重复\n",
    "duplicates = coords.value_counts()\n",
    "print(duplicates[duplicates > 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d697113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords\n",
      "(-81.3811, 19.295)         [GEORGE TOWN, George Town]\n",
      "(-79.3733, 43.7417)                [TORONTO, Toronto]\n",
      "(91.1719, 29.6534)              [LHASA, LHASA, TIBET]\n",
      "(110.3488, 20.0186)          [HAIKOU, HAIKOU, HAINAN]\n",
      "(112.939, 28.228)         [CHANGSHA, CHANGSHA, HUNAN]\n",
      "(116.964, 33.648)           [SUZHOU, SUZHOU, JIANGSU]\n",
      "(117.0207, 36.6702)          [JINAN, JINAN, SHANDONG]\n",
      "(117.2273, 31.8206)             [HEFEI, HEFEI, ANHUI]\n",
      "(118.7789, 32.0608)       [NANJING, NANJING, JIANGSU]\n",
      "(121.6245, 29.8603)        [NINGBO, NINGBO, ZHEJIANG]\n",
      "(125.326, 43.897)       [CHANGCHUN, CHANGCHUN, JILIN]\n",
      "(126.6409, 45.7576)    [HARBIN, HARBIN, HEILONGJIANG]\n",
      "(126.9833, 37.5667)                    [SEOUL, Seoul]\n",
      "Name: City, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# 读取 geojson\n",
    "gdf = gpd.read_file('E:/Documents/UCL/UCLminiproject/demo/City_level_resilience_data_with_clusters.geojson')\n",
    "\n",
    "# 提取经纬度\n",
    "gdf['coords'] = gdf['geometry'].apply(lambda x: (round(x.x, 4), round(x.y, 4)))  # 保留4位小数防止浮点误差\n",
    "\n",
    "# 找到重复的坐标\n",
    "duplicates = gdf[gdf.duplicated(subset='coords', keep=False)]\n",
    "\n",
    "# 查看相同坐标下有哪些City\n",
    "grouped = duplicates.groupby('coords')['City'].unique()\n",
    "\n",
    "print(grouped)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
